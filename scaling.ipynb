{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba79da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import wrangle\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca7186",
   "metadata": {},
   "source": [
    "## 1. Apply the scalers we talked about in this lesson to your data and visualize the results for the unscaled and scaled distribution ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02d52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "df = wrangle.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2d7822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>fips</th>\n",
       "      <th>propertylandusetypeid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27516.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.21</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>296425.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6941.39</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedroomcnt  bathroomcnt  calculatedfinishedsquarefeet  taxvaluedollarcnt  \\\n",
       "0         0.0          0.0                           NaN            27516.0   \n",
       "1         0.0          0.0                           NaN               10.0   \n",
       "2         0.0          0.0                           NaN               10.0   \n",
       "3         0.0          0.0                           NaN             2108.0   \n",
       "4         4.0          2.0                        3633.0           296425.0   \n",
       "\n",
       "   yearbuilt  taxamount    fips  propertylandusetypeid  \n",
       "0        NaN        NaN  6037.0                  261.0  \n",
       "1        NaN        NaN  6037.0                  261.0  \n",
       "2        NaN        NaN  6037.0                  261.0  \n",
       "3        NaN     174.21  6037.0                  261.0  \n",
       "4     2005.0    6941.39  6037.0                  261.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aquired data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287ef960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2152864 entries, 0 to 2152863\n",
      "Data columns (total 8 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   bedroomcnt                    float64\n",
      " 1   bathroomcnt                   float64\n",
      " 2   calculatedfinishedsquarefeet  float64\n",
      " 3   taxvaluedollarcnt             float64\n",
      " 4   yearbuilt                     float64\n",
      " 5   taxamount                     float64\n",
      " 6   fips                          float64\n",
      " 7   propertylandusetypeid         float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 131.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Check data to ensure it is all continuous data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514228e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle.prep_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b05c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the datasets\n",
    "train, validate, test = wrangle.split_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1739894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it out\n",
    "print(f\"train: {train.shape}\")\n",
    "print(f\"validate: {validate.shape}\")\n",
    "print(f\"test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81200b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize before scaling\n",
    "for col in train.columns:\n",
    "    plt.figure()\n",
    "    plt.hist(train[col], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling fit\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "scaler.fit(train)\n",
    "\n",
    "train_scaled = scaler.transform(train)\n",
    "validate_scaled = scaler.transform(validate)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the scaled data\n",
    "for col in train_scaled.columns:\n",
    "    plt.figure()\n",
    "    plt.hist(train_scaled[col], bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e086e",
   "metadata": {},
   "source": [
    "## 2. Apply the .inverse_transform method to your scaled data. Is the resulting dataset the exact same as the original data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cab5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse transform\n",
    "\n",
    "train_inverse_scaled = scaler.inverse_transform(train_scaled)\n",
    "validate_inverse_scaled = scaler.inverse_transform(validate_scaled)\n",
    "test_inverse_scaled = scaler.inverse_transform(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bd7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inverse_scaled = pd.DataFrame(train_inverse_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the scaled data\n",
    "for col in train_inverse_scaled.columns:\n",
    "    plt.figure()\n",
    "    plt.hist(train_inverse_scaled[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69125925",
   "metadata": {},
   "source": [
    "## 3. Read the documentation for sklearn's QuantileTransformer. Use normal for the output_distribution and apply this scaler to your data. Visualize the result of your data scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa27a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile transformer\n",
    "qt = sklearn.preprocessing.QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "train_quantile_scaled = qt.fit_transform(train)\n",
    "validate_quantile_scaled = qt.transform(validate)\n",
    "test_quantile_scaled = qt.transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd540535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quantile_scaled = pd.DataFrame(train_quantile_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ccca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the scaled data\n",
    "for col in train_quantile_scaled.columns:\n",
    "    plt.figure()\n",
    "    plt.hist(train_quantile_scaled[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52362983",
   "metadata": {},
   "source": [
    "## 4. Use the QuantileTransformer, but omit the output_distribution argument. Visualize your results. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1edec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile transformer\n",
    "qt = sklearn.preprocessing.QuantileTransformer()\n",
    "\n",
    "train_quantile_scaled = qt.fit_transform(train)\n",
    "validate_quantile_scaled = qt.transform(validate)\n",
    "test_quantile_scaled = qt.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c24d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quantile_scaled = pd.DataFrame(train_quantile_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the scaled data\n",
    "for col in train_quantile_scaled.columns:\n",
    "    plt.figure()\n",
    "    plt.hist(train_quantile_scaled[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d6aee",
   "metadata": {},
   "source": [
    "## 5. Based on the work you've done, choose a scaling method for your dataset. Write a function within your prepare.py that accepts as input the train, validate, and test data splits, and returns the scaled versions of each. Be sure to only learn the parameters for scaling from your training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad73bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               to_scale):\n",
    "    #duplicate data for scaling\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = test.copy()\n",
    "    test_scaled = test.copy()\n",
    "\n",
    "    #Make Scaler MinMax\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    #Fit Scaler\n",
    "    scaler.fit(train[to_scale])\n",
    "\n",
    "    #Use Scaler\n",
    "    train_scaled[to_scale] = scaler.transform(train[to_scale])\n",
    "    validate_scaled[to_scale] = scaler.transform(validate[to_scale])\n",
    "    test_scaled[to_scale] = scaler.transform(test[to_scale])\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00aecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaf0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e7764",
   "metadata": {},
   "source": [
    "# Instructor functions for scaling \n",
    "Below are visualize_scaler functions from Instructor. Cleaner approach to visualizations will be used for final project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fea5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scale = ['bedrooms','bathrooms','sqft','year_built','sale_tax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_scaler(scaler, df, columns_to_scale, bins=10):\n",
    "    #create subplot structure\n",
    "    fig, axs = plt.subplots(len(columns_to_scale), 2, figsize=(12,12))\n",
    "\n",
    "    #copy the df for scaling\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    #fit and transform the df\n",
    "    df_scaled[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "    #plot the pre-scaled data next to the post-scaled data in one row of a subplot\n",
    "    for (ax1, ax2), col in zip(axs, columns_to_scale):\n",
    "        ax1.hist(df[col], bins=bins)\n",
    "        ax1.set(title=f'{col} before scaling', xlabel=col, ylabel='count')\n",
    "        ax2.hist(df_scaled[col], bins=bins)\n",
    "        ax2.set(title=f'{col} after scaling with {scaler.__class__.__name__}', xlabel=col, ylabel='count')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function with minmax\n",
    "visualize_scaler(scaler=MinMaxScaler(), \n",
    "                 df=train, \n",
    "                 columns_to_scale=to_scale, \n",
    "                 bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function with standard scaler\n",
    "visualize_scaler(scaler=StandardScaler(), \n",
    "                 df=train, \n",
    "                 columns_to_scale=to_scale, \n",
    "                 bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function with robustscaler\n",
    "visualize_scaler(scaler=RobustScaler(), \n",
    "                 df=train, \n",
    "                 columns_to_scale=to_scale, \n",
    "                 bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function using QuantileTransformer\n",
    "visualize_scaler(scaler=QuantileTransformer(output_distribution='normal'), \n",
    "                 df=train,\n",
    "                 columns_to_scale=to_scale, \n",
    "                 bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function using QuantileTransformer\n",
    "visualize_scaler(scaler=QuantileTransformer(), \n",
    "                 df=train,\n",
    "                 columns_to_scale=to_scale, \n",
    "                 bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7947221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
